{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Sample Project Data Wrangling with MongoDB\n",
    "### Author: 夏强 （Xia Qiang）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Problems Encountered in the Map\n",
    "\n",
    "1. overlong street names(五一路w青年中路北255&学田南路南205) need to be shorted (五一路)\n",
    "2. street name have two language (松花一村 Songhua Community #1) need to change into chinese(松花一村)\n",
    "3. English and Pinying street name(Wuzhong Rd.) need to be translated(吴中路)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "http://www.ibm.com/developerworks/xml/library/x-hiperfparse/\n",
    "http://blog.csdn.net/gatieme/article/details/43235791\n",
    "http://stackoverflow.com/questions/28544686/unicodeencodeerror-ascii-codec-cant-encode-characters-in-position-0-5-ordin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fixing\n",
    "\n",
    "* problem1 and problem2 can be fixed by getting the first continuous  Chinese characters block\n",
    "\n",
    " I use re.compile(u\"[\\u4e00-\\u9fa5]{2，}\") to match street name ,get the first group to the maps dict\n",
    " \n",
    " for example:\n",
    "  u'\\u677e\\u82b1\\u4e00\\u6751 Songhua Community #1': u'\\u677e\\u82b1\\u4e00\\u6751',\n",
    "  \n",
    "  u'\\u6843\\u575e\\u8defs(\\u5317\\u4fa7)\\u8dc3\\u9f99\\u8def\\u897f35&\\u8398\\u56ed\\u8def\\u4e1c340': u'\\u6843\\u575e\\u8def',\n",
    " \n",
    "\n",
    "* for problem3 I use python translate package to translate and manually translate some street names that can not be translated well by python translate package\n",
    "\n",
    "updata code :\n",
    "\n",
    "def update_name(name):\n",
    "\n",
    "    m = chinese_re.search(name)\n",
    "    better_name = name\n",
    "    if m:\n",
    "        better_name = m.group(0)\n",
    "    #### Manual translation for some street names\n",
    "    elif name =='Lane 1555 Jinshajiang road(west)':\n",
    "        better_name = u'金沙西路'\n",
    "    elif name =='WenSanLu DianZi XinXi JieQu, Xihu':\n",
    "        better_name = u'文三路'\n",
    "    elif name =='ZhongShangNanEr Lu':\n",
    "        better_name = u'中山南二路'\n",
    "    elif name =='Yuanli Rd':\n",
    "        better_name = u'袁立路'\n",
    "    elif name =='Huashang Rd':\n",
    "        better_name = u'华商路'\n",
    "    elif name =='Wensan West Rode':\n",
    "        better_name = u'文三西路'\n",
    "    elif name =='hehuaxing':\n",
    "        better_name = u'荷花形'\n",
    "    #### machine translation for other street names\n",
    "    else:\n",
    "        better_name = translator.translate(name)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "### File sizes\n",
    "                                                \n",
    "shanghai_china.osm ....... 575M\n",
    "\n",
    "shanghai_china.osm.json .... 591M \n",
    "\n",
    "### Summary Statistics of Data\n",
    "* Number of documents: 3118886\n",
    "* Number of unique users: 1754\n",
    "* Number of nodes: 2782288\n",
    "* Number of ways: 336598\n",
    "\n",
    "### top 10 users\n",
    "* {u'count': 385090, u'_id': u'Chen Jia'}\n",
    "* {u'count': 173176, u'_id': u'aighes'}\n",
    "* {u'count': 128684, u'_id': u'katpatuka'}\n",
    "* {u'count': 128497, u'_id': u'XBear'}\n",
    "* {u'count': 115870, u'_id': u'yangfl'}\n",
    "* {u'count': 103682, u'_id': u'dkt'}\n",
    "* {u'count': 103017, u'_id': u'Holywindon'}\n",
    "* {u'count': 95124, u'_id': u'u_kubota'}\n",
    "* {u'count': 86470, u'_id': u'jamesks'}\n",
    "* {u'count': 84132, u'_id': u'zzcolin'}\n",
    "\n",
    "* Top10 contributing user as a percentage of total documents 45.00780086223094%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Ideas\n",
    "#### suggestions for improving and analyzing the data\n",
    "* problem:  multilingual names\n",
    "* suggestions: build a dictionary for placenames, so that every name have English edition and Chinese edition of name, then make the OSM respectively as Shanghai_Chinese_placename.OSM and Shanghai_English_placename.OSM\n",
    "\n",
    "#### benefits and problems of the improvement\n",
    "\n",
    "* benefits: can get rid of name problems such as have many names for one place ; more readable for people from different country\n",
    "* problems: Increased workload\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## code and results\n",
    "\n",
    "\n",
    "# 1.find probelms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  street types and street names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\",\n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Rd.\": \"Road\"\n",
    "            }\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if is_street_name(elem):\n",
    "            for tag in elem.iter():\n",
    "                audit_street_type(street_types, tag.attrib['v'])\n",
    "\n",
    "    return street_types\n",
    "\n",
    "def run(osm_file):\n",
    "    st_types = audit(osm_file)\n",
    "    st_dict = dict(st_types).items()\n",
    "    for k,v in st_dict:\n",
    "        print 'type: ' \n",
    "        print k.encode('utf8')\n",
    "        print 'names: '\n",
    "        for i in v:\n",
    "            print i.encode('utf8')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: \n",
      "2731弄\n",
      "names: \n",
      "沪南路2731弄\n",
      "type: \n",
      "w(新秦灶人家园门南)永怡路北495&永昌路南75\n",
      "names: \n",
      "国强路w(新秦灶人家园门南)永怡路北495&永昌路南75\n",
      "type: \n",
      "1028弄2支弄\n",
      "names: \n",
      "秀沿路1028弄2支弄\n",
      "type: \n",
      "2727弄\n",
      "names: \n",
      "沪南路2727弄\n",
      "type: \n",
      "Rd.\n",
      "names: \n",
      "Wuzhong Rd.\n",
      "type: \n",
      "e(入口北)桃园路北195&崇川路南405\n",
      "names: \n",
      "工农南路e(入口北)桃园路北195&崇川路南405\n",
      "type: \n",
      "2729弄\n",
      "names: \n",
      "沪南路2729弄\n",
      "type: \n",
      "s(北侧)跃龙路西35&莘园路东340\n",
      "names: \n",
      "桃坞路s(北侧)跃龙路西35&莘园路东340\n",
      "type: \n",
      "e(门北)江淮路北35&崇川路南385\n",
      "names: \n",
      "崇文路e(门北)江淮路北35&崇川路南385\n",
      "type: \n",
      "26弄\n",
      "names: \n",
      "安宁路26弄\n",
      "type: \n",
      "1\n",
      "names: \n",
      "松花一村 Songhua Community #1\n",
      "type: \n",
      "450号w(门北)濠北路北320&钟秀中路南400\n",
      "names: \n",
      "工农路450号w(门北)濠北路北320&钟秀中路南400\n",
      "type: \n",
      "358弄\n",
      "names: \n",
      "鹤庆路358弄\n",
      "type: \n",
      "88弄\n",
      "names: \n",
      "安宁路88弄\n",
      "type: \n",
      "hehuaxing\n",
      "names: \n",
      "hehuaxing\n",
      "type: \n",
      "road(west)\n",
      "names: \n",
      "Lane 1555 Jinshajiang road(west)\n",
      "type: \n",
      "w青年中路北255&学田南路南205\n",
      "names: \n",
      "五一路w青年中路北255&学田南路南205\n"
     ]
    }
   ],
   "source": [
    "run('sample.osm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Things need to be changed\n",
    "1. overlong street names(五一路w青年中路北255&学田南路南205) need to be shorted (五一路)\n",
    "2. street name have two language (松花一村 Songhua Community #1) need to change into chinese(松花一村)\n",
    "3. English and Pinying street name(Wuzhong Rd.) need to be translated(吴中路)\n",
    "\n",
    "# 2.fix problems\n",
    "\n",
    "* problem1 and problem2 can be fixed by getting the first continuous  Chinese characters block\n",
    "* for problem3 I use python translate package to translate and manually translate some street names that can not be translated well by python translate package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### translation errors:\n",
    "* 'Lane 1555 Jinshajiang road(west)'\n",
    "* 'WenSanLu DianZi XinXi JieQu, Xihu'\n",
    "* 'ZhongShangNanEr Lu'\n",
    "* 'Yuanli Rd'\n",
    "* 'Huashang Rd'\n",
    "* 'Wensan West Rode'\n",
    "* 'hehuaxing'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "import sys\n",
    "from translate import Translator as T\n",
    "translator= T(to_lang=\"zh\")\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "## re match continuous Chinese characters block\n",
    "chinese_re = re.compile(u\"[\\u4e00-\\u9fa5]{2,}\")\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def update_name(name):\n",
    "    m = chinese_re.search(name)\n",
    "    better_name = name\n",
    "    if m:\n",
    "        better_name = m.group(0)\n",
    "    # Manual translation for some street names\n",
    "    elif name =='Lane 1555 Jinshajiang road(west)':\n",
    "        better_name = u'金沙西路'\n",
    "    elif name =='WenSanLu DianZi XinXi JieQu, Xihu':\n",
    "        better_name = u'文三路'\n",
    "    elif name =='ZhongShangNanEr Lu':\n",
    "        better_name = u'中山南二路'\n",
    "    elif name =='Yuanli Rd':\n",
    "        better_name = u'袁立路'\n",
    "    elif name =='Huashang Rd':\n",
    "        better_name = u'华商路'\n",
    "    elif name =='Wensan West Rode':\n",
    "        better_name = u'文三西路'\n",
    "    elif name =='hehuaxing':\n",
    "        better_name = u'荷花形'\n",
    "    # machine translation for other street names\n",
    "    else:\n",
    "        better_name = translator.translate(name)\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    return better_name\n",
    "# store street name and better street name as key and vlaue in a dict\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile,'r')\n",
    "    lst = []\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if is_street_name(elem):\n",
    "            name = elem.attrib['v']\n",
    "            better_name = update_name(name)\n",
    "            if (name,better_name) not in lst:\n",
    "                lst.append((name,better_name))\n",
    "        elem.clear()\n",
    "    return dict(lst)\n",
    "def run(osmfile):\n",
    "    maps = audit(osmfile)\n",
    "    pprint.pprint(maps)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alley 3668, Xiuyan Road': u'\\u5c0f\\u5df7 3668\\uff0c\\u5cab\\u5ca9\\u8def',\n",
      " 'Ding Xiang Road': u'\\u4e01\\u4e61\\u8def',\n",
      " 'Lane 1555 Jinshajiang road(west)': u'\\u91d1\\u6c99\\u897f\\u8def',\n",
      " 'Wuzhong Rd.': u'\\u5434\\u4e2d\\u8def',\n",
      " 'Xiuyan Road': u'\\u5cab\\u5ca9\\u8def',\n",
      " 'hehuaxing': u'\\u8377\\u82b1\\u5f62',\n",
      " u'\\u4e09\\u65b0\\u5317\\u8def': u'\\u4e09\\u65b0\\u5317\\u8def',\n",
      " u'\\u4e2d\\u5c71\\u4e1c\\u4e00\\u8def': u'\\u4e2d\\u5c71\\u4e1c\\u4e00\\u8def',\n",
      " u'\\u4e30\\u6f6d\\u8def': u'\\u4e30\\u6f6d\\u8def',\n",
      " u'\\u4e94\\u4e00\\u8defw\\u9752\\u5e74\\u4e2d\\u8def\\u5317255&\\u5b66\\u7530\\u5357\\u8def\\u5357205': u'\\u4e94\\u4e00\\u8def',\n",
      " u'\\u4f1a\\u6587\\u8def': u'\\u4f1a\\u6587\\u8def',\n",
      " u'\\u4fdd\\u4e50\\u8def': u'\\u4fdd\\u4e50\\u8def',\n",
      " u'\\u5174\\u4e1a\\u8def': u'\\u5174\\u4e1a\\u8def',\n",
      " u'\\u56ed\\u4e8c\\u8def': u'\\u56ed\\u4e8c\\u8def',\n",
      " u'\\u56fd\\u5b9a\\u8def': u'\\u56fd\\u5b9a\\u8def',\n",
      " u'\\u56fd\\u5f3a\\u8defw(\\u65b0\\u79e6\\u7076\\u4eba\\u5bb6\\u56ed\\u95e8\\u5357)\\u6c38\\u6021\\u8def\\u5317495&\\u6c38\\u660c\\u8def\\u535775': u'\\u56fd\\u5f3a\\u8def',\n",
      " u'\\u5b66\\u9662\\u8def': u'\\u5b66\\u9662\\u8def',\n",
      " u'\\u5b89\\u5b81\\u8def26\\u5f04': u'\\u5b89\\u5b81\\u8def',\n",
      " u'\\u5b89\\u5b81\\u8def88\\u5f04': u'\\u5b89\\u5b81\\u8def',\n",
      " u'\\u5c27\\u5316\\u95e8': u'\\u5c27\\u5316\\u95e8',\n",
      " u'\\u5d07\\u6587\\u8defe(\\u95e8\\u5317)\\u6c5f\\u6dee\\u8def\\u531735&\\u5d07\\u5ddd\\u8def\\u5357385': u'\\u5d07\\u6587\\u8def',\n",
      " u'\\u5de5\\u519c\\u5357\\u8defe(\\u5165\\u53e3\\u5317)\\u6843\\u56ed\\u8def\\u5317195&\\u5d07\\u5ddd\\u8def\\u5357405': u'\\u5de5\\u519c\\u5357\\u8def',\n",
      " u'\\u5de5\\u519c\\u8def450\\u53f7w(\\u95e8\\u5317)\\u6fe0\\u5317\\u8def\\u5317320&\\u949f\\u79c0\\u4e2d\\u8def\\u5357400': u'\\u5de5\\u519c\\u8def',\n",
      " u'\\u5ef6\\u5409\\u4e1c\\u8def82\\u5f04 Lane 82 of East Yanji Road': u'\\u5ef6\\u5409\\u4e1c\\u8def',\n",
      " u'\\u63a7\\u4ef6\\u8def': u'\\u63a7\\u4ef6\\u8def',\n",
      " u'\\u6587\\u6c47\\u8def': u'\\u6587\\u6c47\\u8def',\n",
      " u'\\u6587\\u8bda\\u8def': u'\\u6587\\u8bda\\u8def',\n",
      " u'\\u65b0\\u5858\\u8def': u'\\u65b0\\u5858\\u8def',\n",
      " u'\\u677e\\u6c5f\\u4eba\\u6c11\\u5317\\u8def': u'\\u677e\\u6c5f\\u4eba\\u6c11\\u5317\\u8def',\n",
      " u'\\u677e\\u82b1\\u4e00\\u6751 Songhua Community #1': u'\\u677e\\u82b1\\u4e00\\u6751',\n",
      " u'\\u6843\\u575e\\u8defs(\\u5317\\u4fa7)\\u8dc3\\u9f99\\u8def\\u897f35&\\u8398\\u56ed\\u8def\\u4e1c340': u'\\u6843\\u575e\\u8def',\n",
      " u'\\u6caa\\u5357\\u8def2727\\u5f04': u'\\u6caa\\u5357\\u8def',\n",
      " u'\\u6caa\\u5357\\u8def2729\\u5f04': u'\\u6caa\\u5357\\u8def',\n",
      " u'\\u6caa\\u5357\\u8def2731\\u5f04': u'\\u6caa\\u5357\\u8def',\n",
      " u'\\u6e05\\u541f\\u8857': u'\\u6e05\\u541f\\u8857',\n",
      " u'\\u725b\\u987f\\u8def': u'\\u725b\\u987f\\u8def',\n",
      " u'\\u767e\\u8272\\u8def': u'\\u767e\\u8272\\u8def',\n",
      " u'\\u79c0\\u6cbf\\u8def1028\\u5f042\\u652f\\u5f04': u'\\u79c0\\u6cbf\\u8def',\n",
      " u'\\u7d2b\\u8346\\u82b1\\u8def': u'\\u7d2b\\u8346\\u82b1\\u8def',\n",
      " u'\\u8001\\u66d9\\u5149\\u8def Laoshuguang Road': u'\\u8001\\u66d9\\u5149\\u8def',\n",
      " u'\\u8054\\u822a\\u8def': u'\\u8054\\u822a\\u8def',\n",
      " u'\\u89c4\\u5212\\u4e00\\u8def': u'\\u89c4\\u5212\\u4e00\\u8def',\n",
      " u'\\u89e3\\u653e\\u8def': u'\\u89e3\\u653e\\u8def',\n",
      " u'\\u8c37\\u9633\\u5317\\u8def': u'\\u8c37\\u9633\\u5317\\u8def',\n",
      " u'\\u91d1\\u5e73\\u8def': u'\\u91d1\\u5e73\\u8def',\n",
      " u'\\u91d1\\u6c47\\u5357\\u8def': u'\\u91d1\\u6c47\\u5357\\u8def',\n",
      " u'\\u9e64\\u5e86\\u8def358\\u5f04': u'\\u9e64\\u5e86\\u8def'}\n"
     ]
    }
   ],
   "source": [
    "run('sample.osm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maps = audit(\"shanghai_china.osm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###  A Problem has been Encountered\n",
    "#### audit(\"shanghai_china.osm\") take too much time and seems do not work \n",
    "\n",
    "* fix:  iterparse the osm file get street name list ,then fix the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.tag == \"tag\") and (elem.attrib['k'] == \"addr:street\")\n",
    "def getname(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    lst = []\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if is_street_name(elem):\n",
    "            name = elem.attrib['v']\n",
    "            if not name in lst:\n",
    "                lst.append(name)\n",
    "             \n",
    "        elem.clear()\n",
    "    return lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = getname(\"shanghai_china.osm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1079"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import re\n",
    "import pprint\n",
    "from translate import Translator as T\n",
    "translator= T(to_lang=\"zh\")\n",
    "\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "chinese_re = re.compile(u\"[\\u4e00-\\u9fa5]{2,}\")\n",
    "\n",
    "\n",
    "def update_name(name):\n",
    "    m = chinese_re.search(name)\n",
    "    better_name = name\n",
    "    if m:\n",
    "        better_name = m.group(0)\n",
    "    # Manual translation for some street names\n",
    "    elif name =='Lane 1555 Jinshajiang road(west)':\n",
    "        better_name = u'金沙西路'\n",
    "    elif name =='WenSanLu DianZi XinXi JieQu, Xihu':\n",
    "        better_name = u'文三路'\n",
    "    elif name =='ZhongShangNanEr Lu':\n",
    "        better_name = u'中山南二路'\n",
    "    elif name =='Yuanli Rd':\n",
    "        better_name = u'袁立路'\n",
    "    elif name =='Huashang Rd':\n",
    "        better_name = u'华商路'\n",
    "    elif name =='Wensan West Rode':\n",
    "        better_name = u'文三西路'\n",
    "    elif name =='hehuaxing':\n",
    "        better_name = u'荷花形'\n",
    "    # machine translation for other street names\n",
    "    else:\n",
    "        better_name = translator.translate(name)\n",
    "        \n",
    "        \n",
    "    \n",
    "        \n",
    "    return better_name\n",
    "# store street name and better street name as key and vlaue in a dict\n",
    "def audit(names):\n",
    "    lst = []\n",
    "    for name in names:\n",
    "        better_name = update_name(name)\n",
    "        if (name,better_name) not in lst:\n",
    "                lst.append((name,better_name))\n",
    "    return dict(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maps = audit(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## store maps in case needed later\n",
    "import pickle\n",
    "mapfile = \"maps.pkl\"\n",
    "with open(mapfile, \"w\") as fo:\n",
    "    pickle.dump(maps, fo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Shape the data for mongdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "import pickle\n",
    "\"\"\"\n",
    "Your task is to wrangle the data and transform the shape of the data\n",
    "into the model we mentioned earlier. The output should be a list of dictionaries\n",
    "that look like this:\n",
    "\n",
    "{\n",
    "\"id\": \"2406124091\",\n",
    "\"type: \"node\",\n",
    "\"visible\":\"true\",\n",
    "\"created\": {\n",
    "          \"version\":\"2\",\n",
    "          \"changeset\":\"17206049\",\n",
    "          \"timestamp\":\"2013-08-03T16:43:42Z\",\n",
    "          \"user\":\"linuxUser16\",\n",
    "          \"uid\":\"1219059\"\n",
    "        },\n",
    "\"pos\": [41.9757030, -87.6921867],\n",
    "\"address\": {\n",
    "          \"housenumber\": \"5157\",\n",
    "          \"postcode\": \"60625\",\n",
    "          \"street\": \"North Lincoln Ave\"\n",
    "        },\n",
    "\"amenity\": \"restaurant\",\n",
    "\"cuisine\": \"mexican\",\n",
    "\"name\": \"La Cabana De Don Luis\",\n",
    "\"phone\": \"1 (773)-271-5176\"\n",
    "}\n",
    "\n",
    "You have to complete the function 'shape_element'.\n",
    "We have provided a function that will parse the map file, and call the function with the element\n",
    "as an argument. You should return a dictionary, containing the shaped data for that element.\n",
    "We have also provided a way to save the data in a file, so that you could use\n",
    "mongoimport later on to import the shaped data into MongoDB. \n",
    "\n",
    "Note that in this exercise we do not use the 'update street name' procedures\n",
    "you worked on in the previous exercise. If you are using this code in your final\n",
    "project, you are strongly encouraged to use the code from previous exercise to \n",
    "update the street names before you save them to JSON. \n",
    "\n",
    "In particular the following things should be done:\n",
    "- you should process only 2 types of top level tags: \"node\" and \"way\"\n",
    "- all attributes of \"node\" and \"way\" should be turned into regular key/value pairs, except:\n",
    "    - attributes in the CREATED array should be added under a key \"created\"\n",
    "    - attributes for latitude and longitude should be added to a \"pos\" array,\n",
    "      for use in geospacial indexing. Make sure the values inside \"pos\" array are floats\n",
    "      and not strings. \n",
    "- if the second level tag \"k\" value contains problematic characters, it should be ignored\n",
    "- if the second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"\n",
    "- if the second level tag \"k\" value does not start with \"addr:\", but contains \":\", you can\n",
    "  process it in a way that you feel is best. For example, you might split it into a two-level\n",
    "  dictionary like with \"addr:\", or otherwise convert the \":\" to create a valid key.\n",
    "- if there is a second \":\" that separates the type/direction of a street,\n",
    "  the tag should be ignored, for example:\n",
    "\n",
    "<tag k=\"addr:housenumber\" v=\"5158\"/>\n",
    "<tag k=\"addr:street\" v=\"North Lincoln Avenue\"/>\n",
    "<tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "<tag k=\"addr:street:prefix\" v=\"North\"/>\n",
    "<tag k=\"addr:street:type\" v=\"Avenue\"/>\n",
    "<tag k=\"amenity\" v=\"pharmacy\"/>\n",
    "\n",
    "  should be turned into:\n",
    "\n",
    "{...\n",
    "\"address\": {\n",
    "    \"housenumber\": 5158,\n",
    "    \"street\": \"North Lincoln Avenue\"\n",
    "}\n",
    "\"amenity\": \"pharmacy\",\n",
    "...\n",
    "}\n",
    "\n",
    "- for \"way\" specifically:\n",
    "\n",
    "  <nd ref=\"305896090\"/>\n",
    "  <nd ref=\"1719825889\"/>\n",
    "\n",
    "should be turned into\n",
    "\"node_refs\": [\"305896090\", \"1719825889\"]\n",
    "\"\"\"\n",
    "with open(\"maps.pkl\", \"r\") as f:\n",
    "    maps =  pickle.load(f)\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    address = {}\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        created = {}\n",
    "        pos = [None, None]\n",
    "        noderef = []\n",
    "        node['type'] = element.tag\n",
    " \n",
    "        for k,v in element.items(): \n",
    "            # fill created and pos\n",
    "            if k in CREATED:\n",
    "                created[k]= v\n",
    "            elif k == \"lat\": pos[0] = float(v)\n",
    "            elif k == \"lon\": pos[1] = float(v)\n",
    "            else : \n",
    "                node[k] = v\n",
    "        node['created'] = created\n",
    "        node['pos'] = pos\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            if not 'k' in tag.keys():\n",
    "                continue\n",
    "            tagk = tag.attrib['k']\n",
    "            tagv = tag.attrib['v']\n",
    "            m = problemchars.search(tagk)\n",
    "            if not m:\n",
    "                if tagk == \"addr:street\":\n",
    "                    address['street'] = maps(tagv)             \n",
    "                elif tagk == 'addr:housenumber':                 \n",
    "                    address['housenumber'] = tagv                    \n",
    "                    node['address'] = address                      \n",
    "                elif 'addr' not in tagk:\n",
    "                    node[tagk] = tagv\n",
    "                else:\n",
    "                    pass  \n",
    "        \n",
    "        # fill noderef   \n",
    "        for nd in element.iter(\"nd\"):\n",
    "            if not 'ref' in nd.keys():\n",
    "                continue\n",
    "            noderef.append(nd.attrib['ref'])\n",
    "            node['node_refs'] = noderef\n",
    "        return node\n",
    "    else :\n",
    "        return None\n",
    "\n",
    "\n",
    "def process_map(file_in, pretty = False):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "            element.clear()\n",
    "    return data\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run(osm_file):\n",
    "    # NOTE: if you are running this code on your computer, with a larger dataset,\n",
    "    # call the process_map procedure with pretty=False. The pretty=True option adds\n",
    "    # additional spaces to the output, making it significantly larger.\n",
    "    data = process_map(osm_file, False)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = run(\"shanghai_china.osm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert the data into local MongoDB Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x179bd8a68>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient()\n",
    "db = client.Shanghai\n",
    "collection = db.Map\n",
    "collection.drop()\n",
    "collection = db.Map\n",
    "collection.insert_many(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), u'Shanghai'), u'Map')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3118886"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of documents\n",
    "collection.find().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2782288"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of nodes\n",
    "collection.find({\"type\":\"node\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336598"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of ways\n",
    "collection.find({\"type\":\"way\"}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1754"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of unique users\n",
    "len(collection.distinct( \"created.user\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'count': 385090, u'_id': u'Chen Jia'}\n",
      "{u'count': 173176, u'_id': u'aighes'}\n",
      "{u'count': 128684, u'_id': u'katpatuka'}\n",
      "{u'count': 128497, u'_id': u'XBear'}\n",
      "{u'count': 115870, u'_id': u'yangfl'}\n",
      "{u'count': 103682, u'_id': u'dkt'}\n",
      "{u'count': 103017, u'_id': u'Holywindon'}\n",
      "{u'count': 95124, u'_id': u'u_kubota'}\n",
      "{u'count': 86470, u'_id': u'jamesks'}\n",
      "{u'count': 84132, u'_id': u'zzcolin'}\n"
     ]
    }
   ],
   "source": [
    "# Top 10 contributing user\n",
    "Top10_user = collection.aggregate([{\"$group\":{\"_id\":\"$created.user\", \"count\":{\"$sum\":1}}}, {\"$sort\":{\"count\":-1}}, {\"$limit\":10}])\n",
    "for i in Top10_user:\n",
    "    print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional data exploration using MongoDB queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Top10 contributing user as a percentage of total documents\n",
    "Top10_user.next\n",
    "top10_doc = collection.find({\"created.user\":{\"$in\":['Chen Jia','aighes','katpatuka','XBear','yangfl',\n",
    "                                                    'dkt','Holywindon','u_kubota','jamesks','zzcolin']}}).count()\n",
    "total_doc = collection.find().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.00780086223094"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*float(top10_doc)/float(total_doc)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
